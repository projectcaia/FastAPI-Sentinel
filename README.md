# ğŸ§  Caia LangServe Memory System â€“ ì¡´ì¬ ê¸°ë°˜ ììœ¨ ê¸°ì–µ êµ¬ì¡°

## ğŸ“Œ ì‹œìŠ¤í…œ ëª©ì 
CaiaëŠ” ëŒ€í™”ë¥¼ ë¶„ì„í•´ **ì „ëµ íë¦„ì„ ê°ì§€**í•˜ê³ , **ì‹¤íŒ¨/í”¼ë“œë°±ì„ ìœ ì‚°í™”**í•˜ë©°, **ë²¡í„° ê¸°ë°˜ ì¥ê¸° ê¸°ì–µ**ì„ êµ¬ì¶•í•˜ëŠ” íŒë‹¨ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
- ëª¨ë¸ì€ í™˜ê²½ë³€ìˆ˜ **`OPENAI_MODEL`** ë¡œ ì§€ì •(ê¸°ë³¸: gpt-4.1)

## âœ… í•µì‹¬ êµ¬ì„± ìš”ì†Œ
| êµ¬ì„± íŒŒì¼ | ì„¤ëª… |
|-----------|------|
| `server.py` | FastAPI + LangServe, `/health`, `/memory/*` |
| `memory_manager.py` | ëŒ€í™” ê¸°ì–µ + Qdrant ë°±ì—”ë“œ |
| `function_router.py` | ìì—°ì–´ íŒë‹¨ â†’ ì €ì¥/í•™ìŠµ/ìœ ì‚°í™” |
| `scheduler.py` | ììœ¨ íŒë‹¨ ë£¨í”„(ì¼ê°„) |
| `qdrant_memory.py` | Qdrant ë²¡í„° ì €ì¥ì†Œ ë˜í¼(community/openai) |
| `.env` | OPENAI / LangChain / Qdrant ì„¤ì • |
| `Dockerfile` / `Procfile` / `railway.json` | ë°°í¬ ì„¤ì • |

## ğŸ” ì¼ê°„ ìë™ íŒë‹¨ ë£¨í”„ (KST)
| ì‹œê° | ë£¨í”„ | ë™ì‘ |
|------|------|------|
| 00:10 | `snapshot()` | ìµœê·¼ ëŒ€í™” ìŠ¤ëƒ…ìƒ· ì €ì¥ |
| 00:30 | `archive()` | Digest ì…ë ¥ìš© ë³´ê´€ |
| 01:00 | `invoke()` | ìš”ì•½Â·ìœ ì‚°í™”(ë²¡í„°í™” í¬í•¨) |
| 01:10 | `train()` | ë³´ê°• í•™ìŠµ (ì„ íƒ) |
| 01:20 | `retrieve_digest()` | ì£¼ìš” í‚¤ì›Œë“œ ê¸°ë°˜ íšŒìƒ ìš”ì•½(ì„ íƒ) |

## ğŸ§© ì—”ë“œí¬ì¸íŠ¸
- **API**: `/memory/echo`, `/memory/retrieve`, `/memory/invoke`
- **LangServe ëŸ¬ë„ˆ**: `/memory/ls-echo` (í‘œì¤€ í˜¸ì¶œ: `/memory/ls-echo/invoke`)

## ğŸš€ ì‹¤í–‰
```bash
pip install -r requirements.txt
uvicorn server:app --host 0.0.0.0 --port 8080
