# memory_manager.py â€” Caia Memory Layer (Option A compatible / v2.4, KST 2025-08-18)
# ëª©ì 
#   - RAW ìš°ì„ (append-only) ê¸°ë¡ + ì„ íƒì  JSONL ë°±ì—…
#   - Qdrant ë²¡í„°ìŠ¤í† ì–´ ì—°ê²°/ë³´ì¥ + ë²¡í„° ì¶”ê°€/ê²€ìƒ‰ í—¬í¼
#   - ì„œë²„/ìŠ¤ì¼€ì¤„ëŸ¬ ë™ì¼ í”„ë¡œì„¸ìŠ¤ì—ì„œ ê³µìœ  ì‹±ê¸€í„´ ì œê³µ(get_shared_memory)
# ë³€ê²½ì (v2.4)
#   - EMBED_DIM ì „ì—­ export (ê¸°ë³¸ ENV/FALLBACK â†’ ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹œ ì‹¤ì œ ê°’ìœ¼ë¡œ ê°±ì‹ )
#   - Qdrant ê²€ìƒ‰ í† í”½ í•„í„°ë¥¼ filter(qmodels.Filter)ë¡œ ì •ì •
#   - ë‚´êµ¬ì„± ë¡œê·¸/ì˜ˆì™¸ ì²˜ë¦¬ ë³´ê°•
#
# ENV
#   OPENAI_API_KEY(ì„ íƒ), QDRANT_URL, QDRANT_API_KEY, QDRANT_COLLECTION(=caia-memory)
#   EMBEDDING_MODEL=text-embedding-3-small, EMBEDDING_DIM=1536
#   CAIA_IMPORTANCE_BASE=0.5
#   RAW_BACKUP_PATH=storage/raw.jsonl
#   RAW_TTL_DAYS=7, RAW_MAX_ITEMS=5000
#   SAFE_BOOT=0 (1ì´ë©´ ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ìƒëµ)

from __future__ import annotations

import os
from typing import List, Dict, Any, Optional, Iterable, Tuple
from urllib.parse import urlparse
from datetime import datetime

# LangChain ë©”ëª¨ë¦¬/ë²¡í„°ìŠ¤í† ì–´
from langchain.memory import ConversationBufferMemory
from langchain.schema import HumanMessage, AIMessage
from langchain.schema.runnable import RunnableLambda
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Qdrant as LC_Qdrant

# Qdrant í´ë¼ì´ì–¸íŠ¸
from qdrant_client import QdrantClient
from qdrant_client.http import models as qmodels

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½/ë°±ì—…/ì„ê³„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_EMBED_MODEL   = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
FALLBACK_EMBED_DIM    = int(os.getenv("EMBEDDING_DIM", "1536"))     # ëª¨ë¸ ë³€ê²½ ë‚´ì„±
SAFE_BOOT             = os.getenv("SAFE_BOOT", "0") == "1"          # ë¶€íŠ¸ ì‹œ ë²¡í„°ìŠ¤í† ì–´ ìŠ¤í‚µ
RAW_BACKUP_PATH       = os.getenv("RAW_BACKUP_PATH", "").strip()    # ì˜ˆ: storage/raw.jsonl
RAW_TTL_DAYS          = int(os.getenv("RAW_TTL_DAYS", "7"))         # L0 TTL ê¸°ë³¸ 7ì¼
RAW_MAX_ITEMS         = int(os.getenv("RAW_MAX_ITEMS", "5000"))     # ë©”ëª¨ë¦¬ ìƒí•œ(ì•ˆì „ì¥ì¹˜)
CAIA_IMPORTANCE_BASE  = float(os.getenv("CAIA_IMPORTANCE_BASE", "0.50"))

QDRANT_COLLECTION     = os.getenv("QDRANT_COLLECTION", "caia-memory")

# âœ… ì„œë²„ì—ì„œ import ê°€ëŠ¥í•œ ì „ì—­ ë‚´ë³´ë‚´ê¸°(ê¸°ë³¸ê°’). ì´ˆê¸°í™” ì´í›„ ì‹¤ì œ ê°’ìœ¼ë¡œ ê°±ì‹ ë¨.
EMBED_DIM: int = FALLBACK_EMBED_DIM

# ìì—°ì–´ ìˆ˜ë™ í•™ìŠµ/ì¤‘ìš”ë„ ì‹ í˜¸(ENVë¡œ ì¬ì •ì˜ ê°€ëŠ¥)
MANUAL_TRIGGERS = tuple(
    (os.getenv("CAIA_MANUAL_TRIGGERS",
               "ê¸°ì–µ,í•™ìŠµ,ì ìš©,ë°˜ì˜,ì €ì¥,ìœ ì‚°í™”,í”¼ë“œë°±,ì „ëµ,íŒë‹¨,ì„¸ì…˜ ì •ë¦¬,ì„¸ì…˜ ë§ˆê°,ì¡´ì¬,ì§„í™”,ì •ì²´ì„±,ê´€ê³„,ì¶”ì–µ"))
    .split(",")
)
DECISION_PATTERNS = tuple(
    (os.getenv("CAIA_DECISION_PATTERNS",
               "ê³ ì •,ë³€ê²½,ìˆ˜ì •,ì² íšŒ,ì œê±°,í—ˆìš©,ê¸ˆì§€,ì„ê³„,ìŠ¤ì¼€ì¤„,ëª©í‘œ,ì±…ì„,ë§ˆê°,ê·œì¹™,ì „ëµëª…,ìš°ì„ ìˆœìœ„,ì„ ì–¸,Codex,Seed3,Existential"))
    .split(",")
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _sanitize_env(s: str) -> str:
    if not s:
        return ""
    s = s.strip()
    for z in ("\u200b", "\u200c", "\u200d", "\ufeff"):
        s = s.replace(z, "")
    return s

def _hex(s: str) -> str:
    return " ".join(f"{ord(c):02X}" for c in s)

def _now_iso() -> str:
    return datetime.utcnow().isoformat()

def _append_jsonl(path: str, obj: dict):
    """ì˜µì…˜: Rawë¥¼ íŒŒì¼ë¡œë„ ë‚¨ê²¨ ì¬ê¸°ë™ ë³µì›/ê°ì‚¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•¨."""
    if not path:
        return
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        import json
        with open(path, "a", encoding="utf-8") as f:
            f.write(json.dumps(obj, ensure_ascii=False) + "\n")
    except Exception as e:
        print(f"[CaiaMemory] RAW ë°±ì—… ì‹¤íŒ¨: {e}")

def _get_embeddings_and_dim() -> Tuple[OpenAIEmbeddings, int]:
    """
    OpenAI ì„ë² ë”© ê°ì²´ì™€ ì°¨ì›ìˆ˜ë¥¼ ë°˜í™˜.
    ì¿¼ë¦¬ ì‹œ ì—ëŸ¬ê°€ ë‚˜ë©´ FALLBACK_EMBED_DIMìœ¼ë¡œ ëŒ€ì²´.
    """
    emb = OpenAIEmbeddings(model=DEFAULT_EMBED_MODEL)
    try:
        dim = len(emb.embed_query("caia dim probe"))
    except Exception:
        dim = FALLBACK_EMBED_DIM
    return emb, dim

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Qdrant ì—°ê²°/ë³´ì¥ (server.pyê°€ ì§ì ‘ í˜¸ì¶œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_qdrant() -> Optional[QdrantClient]:
    q_url_raw = os.getenv("QDRANT_URL", "")
    q_key_raw = os.getenv("QDRANT_API_KEY", "")
    q_url = _sanitize_env(q_url_raw)
    q_key = _sanitize_env(q_key_raw)

    if q_url and not q_url.startswith(("http://", "https://")):
        q_url = "https://" + q_url

    if q_url:
        parsed = urlparse(q_url)
        if not parsed.scheme or not parsed.netloc:
            print(f"[Qdrant] URL í˜•ì‹ ì˜¤ë¥˜: {q_url}  (raw={repr(q_url_raw)}, hex={_hex(q_url_raw)})")
            return None

    if not q_url or not q_key:
        print("[Qdrant] í™˜ê²½ ë¯¸ì„¤ì •(QDRANT_URL/API_KEY)")
        return None

    try:
        client = QdrantClient(url=q_url, api_key=q_key, timeout=30.0)
        return client
    except Exception as e:
        print(f"[Qdrant] í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def ensure_qdrant_collection(
    client: Optional[QdrantClient],
    collection_name: str,
    *,
    ensure_indexes: bool = True
) -> bool:
    """
    ì»¬ë ‰ì…˜/ì¸ë±ìŠ¤ ë³´ì¥. ë°˜í™˜: created ì—¬ë¶€.
    """
    if client is None:
        raise RuntimeError("qdrant_client_unavailable")

    created = False
    try:
        client.get_collection(collection_name)
    except Exception:
        # ì—†ìœ¼ë©´ ìƒì„±
        emb, dim = _get_embeddings_and_dim()
        try:
            client.create_collection(
                collection_name=collection_name,
                vectors_config=qmodels.VectorParams(size=dim, distance=qmodels.Distance.COSINE),
            )
            created = True
        except Exception as e_create:
            if "already exists" not in str(e_create) and getattr(e_create, "status_code", 0) != 409:
                raise

    if ensure_indexes:
        for field, schema in (("topic", "keyword"), ("level", "keyword"), ("ts_unix", "integer")):
            try:
                client.create_payload_index(collection_name, field_name=field, field_schema=schema)
            except Exception:
                pass

    return created


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CaiaMemory (Raw ì „ìš© + ë²¡í„° í—¬í¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class CaiaMemory(ConversationBufferMemory):
    """
    ì›ì¹™:
    - ì´ í´ë˜ìŠ¤ëŠ” **Raw ê¸°ë¡** ìš°ì„ (append-only).
    - ì¦‰ì‹œ ì„ë² ë”©ì€ ì œí•œì ìœ¼ë¡œ(add_vector_memory)ë§Œ ì‚¬ìš©. ë°°ì¹˜(archive/train/legacy)ì—ì„œ ì£¼ë¡œ í™œìš©.
    - history.messages(AIMessage)ì— í‘œì¤€ ë©”íƒ€(type/topic/tags/importance/timestamp/level/source_span) ë¶€ì—¬.
    """
    def __init__(self, session_id: Optional[str] = None, *args, **kwargs):
        kwargs.setdefault("return_messages", True)
        super().__init__(*args, **kwargs)
        object.__setattr__(self, "session_id", session_id)

        if SAFE_BOOT:
            object.__setattr__(self, "vectorstore", None)
            print("[CaiaMemory] SAFE_BOOT=1 â€“ ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ìƒëµ")
            return

        client = make_qdrant()
        if not client:
            object.__setattr__(self, "vectorstore", None)
            print("[CaiaMemory] Qdrant ë¯¸ì—°ê²° â€“ vectorstore ë¹„í™œì„±")
            return

        # ì»¬ë ‰ì…˜ ë³´ì¥
        try:
            ensure_qdrant_collection(client, QDRANT_COLLECTION)
        except Exception as e:
            object.__setattr__(self, "vectorstore", None)
            print(f"[CaiaMemory] Qdrant ensure ì‹¤íŒ¨: {e}")
            return

        try:
            embeddings, dim = _get_embeddings_and_dim()
            vectorstore = LC_Qdrant(client=client, collection_name=QDRANT_COLLECTION, embeddings=embeddings)
            object.__setattr__(self, "vectorstore", vectorstore)
            object.__setattr__(self, "embed_dim", dim)
            # ğŸ”¹ ì „ì—­ EMBED_DIMì„ ì‹¤ì œ ê°’ìœ¼ë¡œ ê°±ì‹ (export ìœ ì§€)
            try:
                globals()["EMBED_DIM"] = int(dim)
            except Exception:
                pass
            print(f"[CaiaMemory] Qdrant ì—°ê²° ì„±ê³µ / collection={QDRANT_COLLECTION}, embed={DEFAULT_EMBED_MODEL}({dim})")
        except Exception as e:
            object.__setattr__(self, "vectorstore", None)
            print(f"[CaiaMemory] vectorstore ìƒì„± ì‹¤íŒ¨: {e}")

    # í¸ì˜
    def now_iso(self) -> str:
        return _now_iso()

    @property
    def history(self):
        return self.chat_memory

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Raw Append API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    def echo(self, data: Dict[str, Any]) -> None:
        """
        Raw ë©”ì‹œì§€ 1ê±´ append.
        í—ˆìš© í•„ë“œ: type/topic/tags/content/timestamp/importance/category/(ì˜µì…˜)level/source_span
        ì¤‘ìš”ë„ ê¸°ë³¸ì€ CAIA_IMPORTANCE_BASE ì‚¬ìš©.
        """
        content = (data.get("content") or "").strip()
        ts = data.get("timestamp") or _now_iso()

        # ê¸°ë³¸ ì¤‘ìš”ë„
        try:
            base = float(data.get("importance", CAIA_IMPORTANCE_BASE))
        except Exception:
            base = CAIA_IMPORTANCE_BASE

        # ğŸ“Œ ìì—°ì–´ íŠ¸ë¦¬ê±°/ê²°ì • íŒ¨í„´ ê°ì§€ â†’ ì¤‘ìš”ë„/íƒœê·¸ ê°•í™”
        try:
            if any(t and (t in content) for t in MANUAL_TRIGGERS):
                base = max(base, 0.85)
                tags = set(data.get("tags", [])); tags.add("manual-feedback"); data["tags"] = list(tags)
            elif any(p and (p in content) for p in DECISION_PATTERNS):
                base = max(base, 0.70)
                tags = set(data.get("tags", [])); tags.add("implicit-decision"); data["tags"] = list(tags)
        except Exception as e:
            print(f"[CaiaMemory] íŠ¸ë¦¬ê±° ê°ì§€ ì˜ˆì™¸: {e}")

        msg = AIMessage(content=content)
        # í‘œì¤€ ë©”íƒ€ ì„¸íŒ…
        for key, default in [
            ("type", "dialogue"),
            ("topic", "ì¼ë°˜"),
            ("tags", []),
            ("importance", base),
            ("timestamp", ts),
            ("category", None),
            ("level", None),
            ("source_span", None),
        ]:
            setattr(msg, key, data.get(key, default))

        # ë©”ëª¨ë¦¬ ìƒí•œ ì•ˆì „ì¥ì¹˜(ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ì œê±°)
        messages = getattr(self.chat_memory, "messages", [])
        if RAW_MAX_ITEMS > 0 and len(messages) >= RAW_MAX_ITEMS:
            try:
                for i, m in enumerate(messages):
                    if isinstance(m, AIMessage):
                        del messages[i]
                        break
            except Exception as e:
                print(f"[CaiaMemory] RAW ìƒí•œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

        self.chat_memory.add_message(msg)

        # ì˜µì…˜: íŒŒì¼ ë°±ì—…
        if RAW_BACKUP_PATH:
            try:
                backup_obj = {
                    "type": getattr(msg, "type", "dialogue"),
                    "topic": getattr(msg, "topic", "ì¼ë°˜"),
                    "tags": getattr(msg, "tags", []),
                    "content": getattr(msg, "content", ""),
                    "timestamp": getattr(msg, "timestamp", ts),
                    "importance": getattr(msg, "importance", 0.0),
                    "level": getattr(msg, "level", None),
                    "source_span": getattr(msg, "source_span", None),
                    "session_id": self.session_id,
                }
                _append_jsonl(RAW_BACKUP_PATH, backup_obj)
            except Exception as e:
                print(f"[CaiaMemory] RAW ë°±ì—… ì˜ˆì™¸: {e}")

    def save(self, data: Dict[str, Any]) -> None:
        self.echo(data)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Vector Add (ë°°ì¹˜/ë³´ì¡°ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    def add_vector_memory(self, text: str, metadata: Optional[Dict[str, Any]] = None) -> None:
        """
        ë°°ì¹˜(merge/legacy/train) ë˜ëŠ” ë³´ì¡°(invoke)ì—ì„œ í˜¸ì¶œ.
        """
        vs = getattr(self, "vectorstore", None)
        if not vs or not text:
            return
        md = dict(metadata or {})
        md.setdefault("ts", _now_iso())
        try:
            vs.add_texts([text], metadatas=[md])
        except Exception as e:
            print(f"[CaiaMemory] vector add ì‹¤íŒ¨: {e}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Vector Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    def vector_search(self, query: str, *, top_k: int = 5, topics_any: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        Qdrant ìœ ì‚¬ë„ ê²€ìƒ‰. ë°˜í™˜: [{text, score, metadata}, ...]
        í† í”½ í•„í„°: qmodels.Filter ì‚¬ìš© (MatchAny)
        """
        vs = getattr(self, "vectorstore", None)
        if not vs or not query:
            return []
        q = query.strip()
        try:
            q_filter = None
            if topics_any:
                q_filter = qmodels.Filter(
                    should=[qmodels.FieldCondition(
                        key="topic",
                        match=qmodels.MatchAny(any=topics_any)
                    )]
                )
            docs_scores = vs.similarity_search_with_score(q, k=max(1, int(top_k)), filter=q_filter)
            out: List[Dict[str, Any]] = []
            for doc, score in docs_scores:
                out.append({
                    "text": doc.page_content,
                    "score": float(score) if score is not None else 0.0,
                    "metadata": dict(getattr(doc, "metadata", {}) or {}),
                })
            return out
        except Exception as e:
            print(f"[CaiaMemory] vector search ì‹¤íŒ¨: {e}")
            return []

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Raw ì¡°íšŒ/ì •ë¦¬ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    def iter_raw(self) -> Iterable[Dict[str, Any]]:
        """history.messages â†’ í‘œì¤€ dict"""
        for m in getattr(self.chat_memory, "messages", []):
            if not isinstance(m, AIMessage):
                pass  # í•„ìš” ì‹œ HumanMessage í¬í•¨ í™•ì¥
            yield {
                "type": getattr(m, "type", "dialogue"),
                "topic": getattr(m, "topic", "ì¼ë°˜"),
                "tags": getattr(m, "tags", []),
                "content": getattr(m, "content", ""),
                "timestamp": getattr(m, "timestamp", None),
                "importance": getattr(m, "importance", 0.0),
                "level": getattr(m, "level", None),
                "source_span": getattr(m, "source_span", None),
            }

    def list_raw(
        self,
        *,
        min_importance: float = 0.0,
        since_ts: Optional[str] = None,
        topic: Optional[str] = None,
        limit: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        ë°°ì¹˜ì—ì„œ ì‚¬ìš©í•  í•„í„°ë§ëœ Raw ì¡°íšŒ.
        - min_importance ì´ìƒ
        - since_ts(ISO) ì´í›„
        - topic ì¼ì¹˜(ì˜µì…˜)
        """
        from datetime import datetime as _dt

        def _to_ts(s: Optional[str]) -> float:
            if not s:
                return 0.0
            try:
                return _dt.fromisoformat(s.replace("Z", "+00:00")).timestamp()
            except Exception:
                return 0.0

        since_unix = _to_ts(since_ts) if since_ts else 0.0
        out: List[Dict[str, Any]] = []
        for it in self.iter_raw():
            if it["importance"] < min_importance:
                continue
            if since_unix and _to_ts(it.get("timestamp")) < since_unix:
                continue
            if topic and it.get("topic") != topic:
                continue
            out.append(it)

        if limit is not None:
            out = out[-limit:]
        return out

    def prune_ttl(self, days: Optional[int] = None) -> int:
        """
        L0 TTL ì •ë¦¬(ê¸°ë³¸ RAW_TTL_DAYS). ë°˜í™˜: ì‚­ì œ ìˆ˜
        - ì¤‘ìš” ìš”ì•½(L1/L2/L3) ê´€ë¦¬ê°€ ë³„ë„ë¡œ ì´ë¤„ì§€ë¯€ë¡œ L0ëŠ” ê°€ë³ê²Œ ìœ ì§€
        """
        ttl_days = RAW_TTL_DAYS if days is None else max(0, days)
        if ttl_days <= 0:
            return 0

        from datetime import datetime as _dt, timedelta as _td
        cutoff = _dt.utcnow() - _td(days=ttl_days)

        kept = []
        removed = 0
        for m in getattr(self.chat_memory, "messages", []):
            ts = getattr(m, "timestamp", None)
            try:
                tsv = _dt.fromisoformat(str(ts).replace("Z", "+00:00")) if ts else None
            except Exception:
                tsv = None
            if tsv and tsv < cutoff:
                removed += 1
                continue
            kept.append(m)

        try:
            self.chat_memory.messages = kept
        except Exception:
            pass
        if removed:
            print(f"[CaiaMemory] TTL ì •ë¦¬: {removed}ê±´ ì œê±°(> {ttl_days}d)")
        return removed


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangServeìš© ê¸°ë³¸ ì‹¤í–‰ í•¨ìˆ˜(ì§€ì—° ì„í¬íŠ¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def echo_fn(messages: List[HumanMessage]) -> List[AIMessage]:
    from function_router import CaiaFunctionRouter
    router = CaiaFunctionRouter(get_shared_memory())
    last = messages[-1].content if messages else ""
    router.analyze_and_route([{"type": "human", "content": last}], topic="ls-echo")
    return [AIMessage(content=f"Caia ê¸°ì–µ ë³µì›: {last}")]

# Runnable for LangServe
memory_runnable = RunnableLambda(echo_fn)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Shared Memory Singleton
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_GLOBAL_MEMORY: Optional[CaiaMemory] = None
def get_shared_memory() -> CaiaMemory:
    global _GLOBAL_MEMORY
    if _GLOBAL_MEMORY is None:
        _GLOBAL_MEMORY = CaiaMemory(session_id="caia-shared")
    return _GLOBAL_MEMORY


# ëª¨ë“ˆ export ëª…ì‹œ(ê°€ë…ì„±/ì •ì  ë¶„ì„ ë³´ì¡°)
__all__ = [
    "CaiaMemory",
    "get_shared_memory",
    "make_qdrant",
    "ensure_qdrant_collection",
    "QDRANT_COLLECTION",
    "EMBED_DIM",
]
